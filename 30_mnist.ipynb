{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-71e12f4bac70>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "x_test = mnist.test.images\n",
    "y_train = mnist.train.labels\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # 로우 하나가 이미지 하나를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape # one hot encoding으로 제공된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중분류 : softmax 사용\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.constant(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.variable_scope.get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝을 안할시에는 밑의 코드 사용\n",
    "# w = tf.Variable(tf.random_uniform([784,10]))\n",
    "# b = tf.Variable(tf.random_uniform([10]))\n",
    "\n",
    "# w1 = tf.Variable(tf.random_uniform([784,10]))\n",
    "# b1 = tf.Variable(tf.random_uniform([10]))\n",
    "# w2 = tf.Variable(tf.random_uniform([100,10]))\n",
    "# b2 = tf.Variable(tf.random_uniform([10]))\n",
    "# 784,10은 맞추고 나머지는 하이퍼파라미터로 설정\n",
    "w1 = tf.get_variable( 'w1',[784,100], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "b1 = tf.get_variable( 'b1',[100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "w2 = tf.get_variable( 'w2',[100,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable( 'b2',[10], initializer=tf.contrib.layers.xavier_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = tf.matmul(x,w1)+b1\n",
    "lay1 = tf.nn.relu(z1) # 확률값 추출 # 학습이 잘 안된다면 relu를 사용할 필요가 있다. 하지만 최종은 softmax를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = tf.matmul(lay1,w2)+b2\n",
    "hx = tf.nn.softmax(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-51b38eb5a0ce>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_i=tf.nn.softmax_cross_entropy_with_logits(logits=z2,labels=y)\n",
    "cost = tf.reduce_mean( cost_i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1) #learning rate\n",
    "train = optimizer.minimize(cost)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.270411\n",
      "1 2.1789641\n",
      "2 2.101808\n",
      "3 2.030565\n",
      "4 1.9622352\n",
      "5 1.8954581\n",
      "6 1.8299409\n",
      "7 1.7655761\n",
      "8 1.702594\n",
      "9 1.6413369\n",
      "10 1.5821023\n",
      "11 1.5251667\n",
      "12 1.4706892\n",
      "13 1.418769\n",
      "14 1.3694724\n",
      "15 1.322776\n",
      "16 1.2786577\n",
      "17 1.2370684\n",
      "18 1.1979442\n",
      "19 1.1611854\n",
      "20 1.1266565\n",
      "21 1.09428\n",
      "22 1.0639147\n",
      "23 1.0354416\n",
      "24 1.008727\n",
      "25 0.9836521\n",
      "26 0.96009773\n",
      "27 0.93796366\n",
      "28 0.9171459\n",
      "29 0.8975406\n",
      "30 0.8790569\n",
      "31 0.8616093\n",
      "32 0.8451274\n",
      "33 0.8295435\n",
      "34 0.8147902\n",
      "35 0.80080754\n",
      "36 0.7875361\n",
      "37 0.77492684\n",
      "38 0.7629317\n",
      "39 0.7515107\n",
      "40 0.7406229\n",
      "41 0.7302316\n",
      "42 0.7203061\n",
      "43 0.71081334\n",
      "44 0.7017283\n",
      "45 0.6930258\n",
      "46 0.6846798\n",
      "47 0.6766688\n",
      "48 0.66897494\n",
      "49 0.6615756\n",
      "50 0.6544567\n",
      "51 0.64760184\n",
      "52 0.640995\n",
      "53 0.634624\n",
      "54 0.6284767\n",
      "55 0.6225405\n",
      "56 0.61680555\n",
      "57 0.6112626\n",
      "58 0.6059023\n",
      "59 0.6007136\n",
      "60 0.59568936\n",
      "61 0.5908226\n",
      "62 0.58610535\n",
      "63 0.58153003\n",
      "64 0.5770896\n",
      "65 0.57277864\n",
      "66 0.5685904\n",
      "67 0.56452\n",
      "68 0.560563\n",
      "69 0.5567142\n",
      "70 0.5529692\n",
      "71 0.54932356\n",
      "72 0.5457734\n",
      "73 0.5423161\n",
      "74 0.5389479\n",
      "75 0.53566444\n",
      "76 0.53246355\n",
      "77 0.52934104\n",
      "78 0.52629334\n",
      "79 0.523318\n",
      "80 0.5204126\n",
      "81 0.5175754\n",
      "82 0.5148031\n",
      "83 0.5120937\n",
      "84 0.50944483\n",
      "85 0.5068547\n",
      "86 0.5043213\n",
      "87 0.5018425\n",
      "88 0.49941686\n",
      "89 0.49704263\n",
      "90 0.49471804\n",
      "91 0.49244112\n",
      "92 0.49021065\n",
      "93 0.48802528\n",
      "94 0.48588336\n",
      "95 0.4837837\n",
      "96 0.4817247\n",
      "97 0.47970548\n",
      "98 0.4777248\n",
      "99 0.47578183\n",
      "100 0.47387508\n",
      "101 0.4720037\n",
      "102 0.47016627\n",
      "103 0.4683617\n",
      "104 0.4665892\n",
      "105 0.46484807\n",
      "106 0.46313694\n",
      "107 0.46145514\n",
      "108 0.45980206\n",
      "109 0.45817676\n",
      "110 0.4565786\n",
      "111 0.455007\n",
      "112 0.4534612\n",
      "113 0.45194057\n",
      "114 0.45044416\n",
      "115 0.44897202\n",
      "116 0.44752315\n",
      "117 0.44609696\n",
      "118 0.44469276\n",
      "119 0.44331005\n",
      "120 0.4419483\n",
      "121 0.44060704\n",
      "122 0.43928587\n",
      "123 0.43798408\n",
      "124 0.43670127\n",
      "125 0.43543687\n",
      "126 0.4341906\n",
      "127 0.43296194\n",
      "128 0.4317505\n",
      "129 0.43055585\n",
      "130 0.4293779\n",
      "131 0.4282163\n",
      "132 0.42707056\n",
      "133 0.4259402\n",
      "134 0.4248247\n",
      "135 0.4237242\n",
      "136 0.4226382\n",
      "137 0.42156652\n",
      "138 0.4205087\n",
      "139 0.41946444\n",
      "140 0.41843346\n",
      "141 0.41741526\n",
      "142 0.41640988\n",
      "143 0.41541687\n",
      "144 0.41443604\n",
      "145 0.41346726\n",
      "146 0.41251028\n",
      "147 0.41156456\n",
      "148 0.4106301\n",
      "149 0.40970653\n",
      "150 0.4087937\n",
      "151 0.40789118\n",
      "152 0.40699875\n",
      "153 0.4061165\n",
      "154 0.40524384\n",
      "155 0.40438086\n",
      "156 0.40352756\n",
      "157 0.4026836\n",
      "158 0.401849\n",
      "159 0.40102345\n",
      "160 0.4002069\n",
      "161 0.39939916\n",
      "162 0.3985997\n",
      "163 0.39780852\n",
      "164 0.3970255\n",
      "165 0.39625058\n",
      "166 0.39548346\n",
      "167 0.39472446\n",
      "168 0.3939731\n",
      "169 0.39322928\n",
      "170 0.39249268\n",
      "171 0.39176342\n",
      "172 0.39104128\n",
      "173 0.3903261\n",
      "174 0.3896176\n",
      "175 0.38891584\n",
      "176 0.38822073\n",
      "177 0.38753223\n",
      "178 0.38685012\n",
      "179 0.38617426\n",
      "180 0.38550457\n",
      "181 0.38484105\n",
      "182 0.38418347\n",
      "183 0.3835318\n",
      "184 0.38288593\n",
      "185 0.38224557\n",
      "186 0.38161102\n",
      "187 0.38098195\n",
      "188 0.3803583\n",
      "189 0.37974015\n",
      "190 0.37912744\n",
      "191 0.37851986\n",
      "192 0.3779173\n",
      "193 0.3773198\n",
      "194 0.37672728\n",
      "195 0.37613967\n",
      "196 0.3755568\n",
      "197 0.37497827\n",
      "198 0.3744043\n",
      "199 0.3738347\n",
      "200 0.37326974\n",
      "201 0.37270927\n",
      "202 0.37215313\n",
      "203 0.37160116\n",
      "204 0.37105352\n",
      "205 0.37051013\n",
      "206 0.3699708\n",
      "207 0.36943558\n",
      "208 0.3689044\n",
      "209 0.36837712\n",
      "210 0.3678537\n",
      "211 0.3673341\n",
      "212 0.36681825\n",
      "213 0.3663061\n",
      "214 0.3657978\n",
      "215 0.3652931\n",
      "216 0.36479202\n",
      "217 0.36429435\n",
      "218 0.36380035\n",
      "219 0.36330965\n",
      "220 0.36282215\n",
      "221 0.3623382\n",
      "222 0.3618574\n",
      "223 0.3613802\n",
      "224 0.36090627\n",
      "225 0.36043555\n",
      "226 0.3599679\n",
      "227 0.35950315\n",
      "228 0.3590415\n",
      "229 0.3585829\n",
      "230 0.35812756\n",
      "231 0.35767508\n",
      "232 0.3572254\n",
      "233 0.35677868\n",
      "234 0.356335\n",
      "235 0.35589424\n",
      "236 0.35545632\n",
      "237 0.3550211\n",
      "238 0.35458857\n",
      "239 0.35415858\n",
      "240 0.35373133\n",
      "241 0.35330665\n",
      "242 0.3528846\n",
      "243 0.35246506\n",
      "244 0.35204798\n",
      "245 0.35163334\n",
      "246 0.35122102\n",
      "247 0.35081115\n",
      "248 0.3504038\n",
      "249 0.3499988\n",
      "250 0.34959605\n",
      "251 0.34919566\n",
      "252 0.34879756\n",
      "253 0.34840164\n",
      "254 0.3480079\n",
      "255 0.34761626\n",
      "256 0.3472269\n",
      "257 0.34683955\n",
      "258 0.34645444\n",
      "259 0.34607145\n",
      "260 0.34569055\n",
      "261 0.34531173\n",
      "262 0.344935\n",
      "263 0.34456044\n",
      "264 0.34418792\n",
      "265 0.34381735\n",
      "266 0.34344888\n",
      "267 0.34308228\n",
      "268 0.3427177\n",
      "269 0.34235498\n",
      "270 0.34199426\n",
      "271 0.34163526\n",
      "272 0.3412782\n",
      "273 0.340923\n",
      "274 0.34056956\n",
      "275 0.34021798\n",
      "276 0.3398681\n",
      "277 0.3395199\n",
      "278 0.33917332\n",
      "279 0.33882847\n",
      "280 0.33848524\n",
      "281 0.33814374\n",
      "282 0.337804\n",
      "283 0.3374657\n",
      "284 0.33712906\n",
      "285 0.33679393\n",
      "286 0.33646044\n",
      "287 0.33612856\n",
      "288 0.33579826\n",
      "289 0.33546954\n",
      "290 0.33514237\n",
      "291 0.33481672\n",
      "292 0.33449253\n",
      "293 0.33416986\n",
      "294 0.33384866\n",
      "295 0.33352888\n",
      "296 0.3332105\n",
      "297 0.33289364\n",
      "298 0.33257812\n",
      "299 0.33226386\n",
      "300 0.33195096\n",
      "301 0.3316393\n",
      "302 0.33132905\n",
      "303 0.33102018\n",
      "304 0.33071265\n",
      "305 0.33040637\n",
      "306 0.33010137\n",
      "307 0.32979763\n",
      "308 0.32949516\n",
      "309 0.32919395\n",
      "310 0.3288941\n",
      "311 0.32859543\n",
      "312 0.32829782\n",
      "313 0.3280015\n",
      "314 0.32770625\n",
      "315 0.3274122\n",
      "316 0.3271193\n",
      "317 0.32682762\n",
      "318 0.3265371\n",
      "319 0.32624784\n",
      "320 0.32595977\n",
      "321 0.32567286\n",
      "322 0.32538715\n",
      "323 0.32510257\n",
      "324 0.32481918\n",
      "325 0.3245369\n",
      "326 0.32425565\n",
      "327 0.32397556\n",
      "328 0.32369635\n",
      "329 0.3234181\n",
      "330 0.32314083\n",
      "331 0.3228647\n",
      "332 0.32258934\n",
      "333 0.32231516\n",
      "334 0.32204193\n",
      "335 0.32176968\n",
      "336 0.3214983\n",
      "337 0.32122812\n",
      "338 0.32095903\n",
      "339 0.32069072\n",
      "340 0.32042333\n",
      "341 0.3201569\n",
      "342 0.31989133\n",
      "343 0.31962678\n",
      "344 0.31936306\n",
      "345 0.31910035\n",
      "346 0.31883857\n",
      "347 0.31857777\n",
      "348 0.3183181\n",
      "349 0.31805947\n",
      "350 0.3178016\n",
      "351 0.31754452\n",
      "352 0.31728828\n",
      "353 0.31703287\n",
      "354 0.31677827\n",
      "355 0.3165246\n",
      "356 0.3162717\n",
      "357 0.3160196\n",
      "358 0.31576818\n",
      "359 0.31551772\n",
      "360 0.31526804\n",
      "361 0.31501925\n",
      "362 0.31477126\n",
      "363 0.31452405\n",
      "364 0.31427762\n",
      "365 0.3140321\n",
      "366 0.3137872\n",
      "367 0.31354296\n",
      "368 0.31329954\n",
      "369 0.31305668\n",
      "370 0.31281444\n",
      "371 0.31257305\n",
      "372 0.3123324\n",
      "373 0.3120926\n",
      "374 0.31185338\n",
      "375 0.3116149\n",
      "376 0.31137702\n",
      "377 0.31113994\n",
      "378 0.31090355\n",
      "379 0.3106679\n",
      "380 0.31043285\n",
      "381 0.31019852\n",
      "382 0.30996484\n",
      "383 0.3097321\n",
      "384 0.30949986\n",
      "385 0.3092684\n",
      "386 0.3090375\n",
      "387 0.30880725\n",
      "388 0.30857787\n",
      "389 0.30834916\n",
      "390 0.3081212\n",
      "391 0.30789384\n",
      "392 0.30766732\n",
      "393 0.30744126\n",
      "394 0.3072159\n",
      "395 0.30699122\n",
      "396 0.3067673\n",
      "397 0.30654404\n",
      "398 0.30632123\n",
      "399 0.3060992\n",
      "400 0.30587786\n",
      "401 0.30565724\n",
      "402 0.30543715\n",
      "403 0.30521783\n",
      "404 0.30499917\n",
      "405 0.30478096\n",
      "406 0.30456337\n",
      "407 0.30434647\n",
      "408 0.30413038\n",
      "409 0.30391484\n",
      "410 0.30369994\n",
      "411 0.30348557\n",
      "412 0.30327195\n",
      "413 0.30305874\n",
      "414 0.30284595\n",
      "415 0.30263373\n",
      "416 0.30242202\n",
      "417 0.30221084\n",
      "418 0.30200028\n",
      "419 0.30179027\n",
      "420 0.3015809\n",
      "421 0.30137193\n",
      "422 0.30116355\n",
      "423 0.3009557\n",
      "424 0.30074832\n",
      "425 0.3005415\n",
      "426 0.30033505\n",
      "427 0.30012906\n",
      "428 0.29992357\n",
      "429 0.29971835\n",
      "430 0.29951364\n",
      "431 0.29930952\n",
      "432 0.29910582\n",
      "433 0.29890263\n",
      "434 0.29870018\n",
      "435 0.29849815\n",
      "436 0.2982967\n",
      "437 0.29809582\n",
      "438 0.29789543\n",
      "439 0.29769546\n",
      "440 0.29749608\n",
      "441 0.2972972\n",
      "442 0.29709882\n",
      "443 0.29690075\n",
      "444 0.29670298\n",
      "445 0.29650566\n",
      "446 0.29630882\n",
      "447 0.29611242\n",
      "448 0.29591644\n",
      "449 0.2957209\n",
      "450 0.2955259\n",
      "451 0.2953315\n",
      "452 0.29513752\n",
      "453 0.29494408\n",
      "454 0.29475114\n",
      "455 0.2945587\n",
      "456 0.29436687\n",
      "457 0.29417548\n",
      "458 0.29398444\n",
      "459 0.2937939\n",
      "460 0.29360366\n",
      "461 0.2934136\n",
      "462 0.29322404\n",
      "463 0.29303482\n",
      "464 0.29284605\n",
      "465 0.29265776\n",
      "466 0.29247004\n",
      "467 0.2922828\n",
      "468 0.292096\n",
      "469 0.29190964\n",
      "470 0.29172364\n",
      "471 0.29153806\n",
      "472 0.29135287\n",
      "473 0.29116803\n",
      "474 0.2909835\n",
      "475 0.29079932\n",
      "476 0.29061553\n",
      "477 0.29043207\n",
      "478 0.29024902\n",
      "479 0.29006642\n",
      "480 0.2898841\n",
      "481 0.28970206\n",
      "482 0.2895205\n",
      "483 0.28933933\n",
      "484 0.28915855\n",
      "485 0.288978\n",
      "486 0.2887981\n",
      "487 0.28861848\n",
      "488 0.28843915\n",
      "489 0.2882603\n",
      "490 0.28808188\n",
      "491 0.287904\n",
      "492 0.28772655\n",
      "493 0.2875494\n",
      "494 0.2873725\n",
      "495 0.28719583\n",
      "496 0.2870196\n",
      "497 0.2868437\n",
      "498 0.28666806\n",
      "499 0.2864928\n",
      "500 0.28631786\n",
      "501 0.2861433\n",
      "502 0.28596908\n",
      "503 0.28579518\n",
      "504 0.2856216\n",
      "505 0.28544828\n",
      "506 0.28527528\n",
      "507 0.2851026\n",
      "508 0.28493023\n",
      "509 0.28475815\n",
      "510 0.2845864\n",
      "511 0.28441498\n",
      "512 0.28424388\n",
      "513 0.2840731\n",
      "514 0.28390267\n",
      "515 0.28373256\n",
      "516 0.2835628\n",
      "517 0.28339356\n",
      "518 0.28322467\n",
      "519 0.2830561\n",
      "520 0.28288785\n",
      "521 0.28271994\n",
      "522 0.28255233\n",
      "523 0.28238505\n",
      "524 0.2822181\n",
      "525 0.28205132\n",
      "526 0.28188497\n",
      "527 0.2817188\n",
      "528 0.2815528\n",
      "529 0.28138712\n",
      "530 0.28122166\n",
      "531 0.28105646\n",
      "532 0.28089157\n",
      "533 0.28072694\n",
      "534 0.2805626\n",
      "535 0.28039855\n",
      "536 0.28023484\n",
      "537 0.28007153\n",
      "538 0.2799085\n",
      "539 0.27974582\n",
      "540 0.27958342\n",
      "541 0.27942124\n",
      "542 0.27925944\n",
      "543 0.27909794\n",
      "544 0.27893683\n",
      "545 0.27877596\n",
      "546 0.27861536\n",
      "547 0.27845496\n",
      "548 0.27829483\n",
      "549 0.27813497\n",
      "550 0.27797544\n",
      "551 0.27781615\n",
      "552 0.27765724\n",
      "553 0.27749866\n",
      "554 0.2773404\n",
      "555 0.27718246\n",
      "556 0.27702472\n",
      "557 0.27686733\n",
      "558 0.27671018\n",
      "559 0.27655336\n",
      "560 0.2763968\n",
      "561 0.2762405\n",
      "562 0.2760845\n",
      "563 0.27592897\n",
      "564 0.27577367\n",
      "565 0.27561864\n",
      "566 0.27546385\n",
      "567 0.27530938\n",
      "568 0.27515522\n",
      "569 0.27500135\n",
      "570 0.27484766\n",
      "571 0.27469438\n",
      "572 0.27454138\n",
      "573 0.2743887\n",
      "574 0.27423623\n",
      "575 0.27408397\n",
      "576 0.27393198\n",
      "577 0.2737802\n",
      "578 0.27362865\n",
      "579 0.27347738\n",
      "580 0.27332637\n",
      "581 0.2731756\n",
      "582 0.27302516\n",
      "583 0.27287483\n",
      "584 0.27272478\n",
      "585 0.27257502\n",
      "586 0.27242532\n",
      "587 0.2722759\n",
      "588 0.27212664\n",
      "589 0.2719777\n",
      "590 0.27182895\n",
      "591 0.2716805\n",
      "592 0.27153224\n",
      "593 0.27138415\n",
      "594 0.2712363\n",
      "595 0.27108875\n",
      "596 0.27094147\n",
      "597 0.27079436\n",
      "598 0.27064753\n",
      "599 0.27050093\n",
      "600 0.27035454\n",
      "601 0.27020827\n",
      "602 0.2700623\n",
      "603 0.2699165\n",
      "604 0.26977092\n",
      "605 0.2696254\n",
      "606 0.26948008\n",
      "607 0.26933506\n",
      "608 0.26919028\n",
      "609 0.2690457\n",
      "610 0.26890132\n",
      "611 0.26875716\n",
      "612 0.2686132\n",
      "613 0.26846948\n",
      "614 0.26832598\n",
      "615 0.2681827\n",
      "616 0.26803958\n",
      "617 0.26789665\n",
      "618 0.26775384\n",
      "619 0.2676113\n",
      "620 0.267469\n",
      "621 0.26732683\n",
      "622 0.26718494\n",
      "623 0.2670433\n",
      "624 0.26690188\n",
      "625 0.26676074\n",
      "626 0.26661965\n",
      "627 0.26647884\n",
      "628 0.26633826\n",
      "629 0.2661978\n",
      "630 0.26605755\n",
      "631 0.2659175\n",
      "632 0.26577762\n",
      "633 0.26563796\n",
      "634 0.26549843\n",
      "635 0.26535907\n",
      "636 0.26522\n",
      "637 0.26508105\n",
      "638 0.26494223\n",
      "639 0.26480365\n",
      "640 0.26466537\n",
      "641 0.26452717\n",
      "642 0.26438922\n",
      "643 0.26425147\n",
      "644 0.26411384\n",
      "645 0.2639765\n",
      "646 0.26383922\n",
      "647 0.26370224\n",
      "648 0.26356533\n",
      "649 0.2634287\n",
      "650 0.26329225\n",
      "651 0.26315603\n",
      "652 0.26302004\n",
      "653 0.26288417\n",
      "654 0.2627484\n",
      "655 0.26261276\n",
      "656 0.26247734\n",
      "657 0.26234207\n",
      "658 0.26220694\n",
      "659 0.26207197\n",
      "660 0.26193714\n",
      "661 0.26180258\n",
      "662 0.26166818\n",
      "663 0.26153392\n",
      "664 0.26139984\n",
      "665 0.26126593\n",
      "666 0.26113224\n",
      "667 0.2609987\n",
      "668 0.2608653\n",
      "669 0.26073223\n",
      "670 0.2605993\n",
      "671 0.2604666\n",
      "672 0.26033413\n",
      "673 0.2602017\n",
      "674 0.26006955\n",
      "675 0.25993752\n",
      "676 0.25980583\n",
      "677 0.25967428\n",
      "678 0.25954297\n",
      "679 0.2594118\n",
      "680 0.25928077\n",
      "681 0.25914997\n",
      "682 0.25901937\n",
      "683 0.25888893\n",
      "684 0.2587587\n",
      "685 0.25862858\n",
      "686 0.25849864\n",
      "687 0.25836897\n",
      "688 0.2582394\n",
      "689 0.25811005\n",
      "690 0.2579807\n",
      "691 0.25785157\n",
      "692 0.25772262\n",
      "693 0.257594\n",
      "694 0.2574655\n",
      "695 0.25733724\n",
      "696 0.25720912\n",
      "697 0.2570812\n",
      "698 0.25695348\n",
      "699 0.25682586\n",
      "700 0.25669837\n",
      "701 0.25657114\n",
      "702 0.256444\n",
      "703 0.25631696\n",
      "704 0.2561901\n",
      "705 0.25606334\n",
      "706 0.2559367\n",
      "707 0.2558103\n",
      "708 0.25568402\n",
      "709 0.2555578\n",
      "710 0.25543177\n",
      "711 0.2553057\n",
      "712 0.2551798\n",
      "713 0.25505406\n",
      "714 0.25492844\n",
      "715 0.25480294\n",
      "716 0.2546777\n",
      "717 0.2545526\n",
      "718 0.25442767\n",
      "719 0.25430292\n",
      "720 0.25417835\n",
      "721 0.25405386\n",
      "722 0.25392964\n",
      "723 0.25380555\n",
      "724 0.25368163\n",
      "725 0.2535578\n",
      "726 0.25343415\n",
      "727 0.2533107\n",
      "728 0.25318742\n",
      "729 0.25306427\n",
      "730 0.25294134\n",
      "731 0.2528185\n",
      "732 0.2526959\n",
      "733 0.25257322\n",
      "734 0.25245073\n",
      "735 0.2523284\n",
      "736 0.2522062\n",
      "737 0.25208423\n",
      "738 0.25196236\n",
      "739 0.25184065\n",
      "740 0.25171915\n",
      "741 0.2515978\n",
      "742 0.25147665\n",
      "743 0.25135562\n",
      "744 0.25123468\n",
      "745 0.2511139\n",
      "746 0.25099313\n",
      "747 0.25087255\n",
      "748 0.25075212\n",
      "749 0.2506318\n",
      "750 0.2505117\n",
      "751 0.25039175\n",
      "752 0.25027204\n",
      "753 0.2501524\n",
      "754 0.250033\n",
      "755 0.2499136\n",
      "756 0.24979448\n",
      "757 0.24967551\n",
      "758 0.24955675\n",
      "759 0.24943821\n",
      "760 0.24931976\n",
      "761 0.2492014\n",
      "762 0.24908324\n",
      "763 0.24896517\n",
      "764 0.2488472\n",
      "765 0.24872933\n",
      "766 0.24861157\n",
      "767 0.24849401\n",
      "768 0.24837653\n",
      "769 0.24825911\n",
      "770 0.24814178\n",
      "771 0.24802454\n",
      "772 0.2479074\n",
      "773 0.24779044\n",
      "774 0.24767354\n",
      "775 0.24755678\n",
      "776 0.2474401\n",
      "777 0.24732357\n",
      "778 0.24720724\n",
      "779 0.24709107\n",
      "780 0.246975\n",
      "781 0.24685916\n",
      "782 0.24674332\n",
      "783 0.24662764\n",
      "784 0.24651207\n",
      "785 0.24639656\n",
      "786 0.24628115\n",
      "787 0.24616583\n",
      "788 0.24605057\n",
      "789 0.24593547\n",
      "790 0.24582045\n",
      "791 0.24570568\n",
      "792 0.24559094\n",
      "793 0.24547628\n",
      "794 0.2453618\n",
      "795 0.24524748\n",
      "796 0.24513324\n",
      "797 0.24501911\n",
      "798 0.2449051\n",
      "799 0.24479128\n",
      "800 0.24467759\n",
      "801 0.24456395\n",
      "802 0.24445039\n",
      "803 0.24433696\n",
      "804 0.2442237\n",
      "805 0.24411052\n",
      "806 0.24399741\n",
      "807 0.24388444\n",
      "808 0.24377164\n",
      "809 0.24365899\n",
      "810 0.24354643\n",
      "811 0.24343404\n",
      "812 0.2433218\n",
      "813 0.24320978\n",
      "814 0.24309787\n",
      "815 0.24298598\n",
      "816 0.2428741\n",
      "817 0.24276236\n",
      "818 0.24265067\n",
      "819 0.24253912\n",
      "820 0.24242756\n",
      "821 0.24231608\n",
      "822 0.24220473\n",
      "823 0.24209343\n",
      "824 0.24198225\n",
      "825 0.24187115\n",
      "826 0.24176021\n",
      "827 0.24164936\n",
      "828 0.24153863\n",
      "829 0.24142802\n",
      "830 0.24131753\n",
      "831 0.24120715\n",
      "832 0.24109693\n",
      "833 0.2409869\n",
      "834 0.24087697\n",
      "835 0.24076718\n",
      "836 0.2406575\n",
      "837 0.24054797\n",
      "838 0.24043864\n",
      "839 0.2403294\n",
      "840 0.24022041\n",
      "841 0.24011147\n",
      "842 0.24000266\n",
      "843 0.239894\n",
      "844 0.23978533\n",
      "845 0.23967682\n",
      "846 0.2395684\n",
      "847 0.23946013\n",
      "848 0.23935196\n",
      "849 0.23924392\n",
      "850 0.23913604\n",
      "851 0.2390283\n",
      "852 0.23892063\n",
      "853 0.23881316\n",
      "854 0.2387057\n",
      "855 0.23859839\n",
      "856 0.23849118\n",
      "857 0.23838416\n",
      "858 0.23827718\n",
      "859 0.23817034\n",
      "860 0.23806368\n",
      "861 0.23795703\n",
      "862 0.23785052\n",
      "863 0.23774406\n",
      "864 0.23763771\n",
      "865 0.23753142\n",
      "866 0.23742531\n",
      "867 0.23731928\n",
      "868 0.23721336\n",
      "869 0.23710753\n",
      "870 0.23700187\n",
      "871 0.23689628\n",
      "872 0.2367908\n",
      "873 0.23668541\n",
      "874 0.23658015\n",
      "875 0.23647496\n",
      "876 0.23636998\n",
      "877 0.23626503\n",
      "878 0.23616019\n",
      "879 0.23605536\n",
      "880 0.2359507\n",
      "881 0.23584609\n",
      "882 0.23574156\n",
      "883 0.23563722\n",
      "884 0.23553306\n",
      "885 0.23542897\n",
      "886 0.23532495\n",
      "887 0.23522106\n",
      "888 0.23511726\n",
      "889 0.23501356\n",
      "890 0.23490998\n",
      "891 0.2348065\n",
      "892 0.23470318\n",
      "893 0.2346\n",
      "894 0.23449685\n",
      "895 0.23439372\n",
      "896 0.23429058\n",
      "897 0.23418748\n",
      "898 0.2340845\n",
      "899 0.23398164\n",
      "900 0.23387887\n",
      "901 0.2337761\n",
      "902 0.23367344\n",
      "903 0.23357081\n",
      "904 0.23346825\n",
      "905 0.23336582\n",
      "906 0.2332635\n",
      "907 0.23316133\n",
      "908 0.23305923\n",
      "909 0.23295733\n",
      "910 0.23285562\n",
      "911 0.23275399\n",
      "912 0.23265247\n",
      "913 0.23255102\n",
      "914 0.23244978\n",
      "915 0.23234868\n",
      "916 0.23224765\n",
      "917 0.23214671\n",
      "918 0.23204583\n",
      "919 0.2319451\n",
      "920 0.23184454\n",
      "921 0.23174411\n",
      "922 0.23164375\n",
      "923 0.2315435\n",
      "924 0.23144329\n",
      "925 0.2313432\n",
      "926 0.23124315\n",
      "927 0.23114315\n",
      "928 0.23104317\n",
      "929 0.23094328\n",
      "930 0.23084348\n",
      "931 0.23074378\n",
      "932 0.23064418\n",
      "933 0.23054469\n",
      "934 0.23044518\n",
      "935 0.23034573\n",
      "936 0.2302463\n",
      "937 0.23014675\n",
      "938 0.23004737\n",
      "939 0.22994804\n",
      "940 0.22984882\n",
      "941 0.22974971\n",
      "942 0.2296508\n",
      "943 0.229552\n",
      "944 0.22945327\n",
      "945 0.22935472\n",
      "946 0.22925623\n",
      "947 0.22915792\n",
      "948 0.2290597\n",
      "949 0.22896154\n",
      "950 0.22886358\n",
      "951 0.2287657\n",
      "952 0.22866797\n",
      "953 0.22857037\n",
      "954 0.22847286\n",
      "955 0.22837546\n",
      "956 0.22827809\n",
      "957 0.22818072\n",
      "958 0.22808336\n",
      "959 0.22798604\n",
      "960 0.22788887\n",
      "961 0.22779183\n",
      "962 0.22769488\n",
      "963 0.22759812\n",
      "964 0.22750142\n",
      "965 0.22740492\n",
      "966 0.22730853\n",
      "967 0.22721222\n",
      "968 0.227116\n",
      "969 0.2270199\n",
      "970 0.22692387\n",
      "971 0.2268278\n",
      "972 0.22673185\n",
      "973 0.2266361\n",
      "974 0.22654037\n",
      "975 0.22644478\n",
      "976 0.22634922\n",
      "977 0.22625373\n",
      "978 0.22615838\n",
      "979 0.22606318\n",
      "980 0.22596808\n",
      "981 0.22587311\n",
      "982 0.22577819\n",
      "983 0.22568336\n",
      "984 0.22558863\n",
      "985 0.2254939\n",
      "986 0.22539924\n",
      "987 0.2253047\n",
      "988 0.22521012\n",
      "989 0.22511566\n",
      "990 0.2250212\n",
      "991 0.22492684\n",
      "992 0.22483262\n",
      "993 0.22473857\n",
      "994 0.22464453\n",
      "995 0.22455065\n",
      "996 0.22445685\n",
      "997 0.22436307\n",
      "998 0.22426939\n",
      "999 0.22417578\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train,{x:x_train})\n",
    "    print(i,sess.run(cost, {x:x_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.1810362e-05, 9.9306376e-08, 3.4412558e-04, 1.6096429e-03,\n",
       "        1.1183321e-06, 4.2345291e-05, 2.1878176e-08, 9.9758363e-01,\n",
       "        7.3820056e-06, 3.3985960e-04]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx,{x:x_test[[0]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hx,{x:x_test[[0]]}).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 \n",
    "aa = sess.run(hx,{x:x_test[[0]]})\n",
    "h = aa.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1028"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h==bb).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
