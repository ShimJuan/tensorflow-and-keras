{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder( tf.float32)\n",
    "y = tf.constant( [1,2,3], tf.float32)\n",
    "\n",
    "# w = tf.Variable(10.0)\n",
    "# b = tf.Variable(10.0)\n",
    "w = tf.get_variable('w1',shape=[1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.get_variable('b1',shape=[1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# 둘중에 학습이 더 잘되는 모델을 선택하여 진행\n",
    "# xavoer, he algorithm (보통은 많이 씀)\n",
    "#tf.contrib.layers.variance_scaling_initializer()(he)\n",
    "\n",
    "\n",
    "hx = w*x + b\n",
    "cost = tf.reduce_mean(tf.square(hx-y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1) #learning rate\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.충분히\n",
    "#2.이전데이터랑 비교해 일정값 이상 변화가 없으면 break로 반복문 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.06063315\n",
      "1 0.046126362\n",
      "2 0.043796454\n",
      "3 0.04171442\n",
      "4 0.039732926\n",
      "5 0.0378456\n",
      "6 0.036047887\n",
      "7 0.034335595\n",
      "8 0.03270464\n",
      "9 0.031151146\n",
      "10 0.029671438\n",
      "11 0.028262014\n",
      "12 0.026919534\n",
      "13 0.02564083\n",
      "14 0.024422878\n",
      "15 0.023262804\n",
      "16 0.022157783\n",
      "17 0.021105273\n",
      "18 0.020102764\n",
      "19 0.01914787\n",
      "20 0.018238328\n",
      "21 0.017371977\n",
      "22 0.016546814\n",
      "23 0.015760822\n",
      "24 0.015012168\n",
      "25 0.014299087\n",
      "26 0.013619854\n",
      "27 0.012972911\n",
      "28 0.012356687\n",
      "29 0.011769739\n",
      "30 0.01121067\n",
      "31 0.01067815\n",
      "32 0.010170927\n",
      "33 0.009687808\n",
      "34 0.009227623\n",
      "35 0.008789308\n",
      "36 0.00837181\n",
      "37 0.007974151\n",
      "38 0.007595364\n",
      "39 0.0072345682\n",
      "40 0.0068909265\n",
      "41 0.006563607\n",
      "42 0.0062518367\n",
      "43 0.005954873\n",
      "44 0.005671999\n",
      "45 0.0054025785\n",
      "46 0.0051459554\n",
      "47 0.0049015195\n",
      "48 0.004668688\n",
      "49 0.004446928\n",
      "50 0.004235694\n",
      "51 0.004034486\n",
      "52 0.0038428453\n",
      "53 0.0036603205\n",
      "54 0.0034864477\n",
      "55 0.0033208386\n",
      "56 0.00316309\n",
      "57 0.0030128413\n",
      "58 0.0028697287\n",
      "59 0.0027334206\n",
      "early stopping..\n"
     ]
    }
   ],
   "source": [
    "hist_loss=[]\n",
    "patience=40\n",
    "min_delta = 0.001\n",
    "for i in range(300):\n",
    "    sess.run(train,{x:[1,2,3]})\n",
    "    c = sess.run(cost,{x:[1,2,3]})\n",
    "    hist_loss.append(c)\n",
    "    print(i,c)\n",
    "    #민델타와 pcnt를 비교\n",
    "    if i>0:\n",
    "        if hist_loss[i-1]-hist_loss[i]>min_delta:\n",
    "            pcnt=0\n",
    "        else:\n",
    "            pcnt+=1\n",
    "        if pcnt>patience:\n",
    "            print('early stopping..')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3]\n",
    "y = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 3 samples\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 29ms/sample - loss: 4.5524\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 3.3321\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 351us/sample - loss: 2.3120\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.4929\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.8718\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 0.4402\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 299us/sample - loss: 0.1825\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 683us/sample - loss: 0.0746\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 257us/sample - loss: 0.0844\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.1733\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.3011\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.4311\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.5353\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 660us/sample - loss: 0.5971\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 331us/sample - loss: 0.6109\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 666us/sample - loss: 0.5804\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.5150\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 309us/sample - loss: 0.4276\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.3314\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 669us/sample - loss: 0.2388\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 315us/sample - loss: 0.1595\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.0999\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.0631\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 311us/sample - loss: 0.0485\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0527\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0702\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0944\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.1189\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 660us/sample - loss: 0.1384\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.1493\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 326us/sample - loss: 0.1501\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 321us/sample - loss: 0.1414\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.1251\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.1043\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 330us/sample - loss: 0.0822\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0619\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0459\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 666us/sample - loss: 0.0353\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0304\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0306\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0342\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 328us/sample - loss: 0.0396\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.0449\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 328us/sample - loss: 0.0487\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 338us/sample - loss: 0.0500\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0486\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 324us/sample - loss: 0.0449\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 330us/sample - loss: 0.0394\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0333\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.0274\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.0225\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0192\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 0.0175\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0172\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0178\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0189\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0198\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 324us/sample - loss: 0.0203\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0200\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0189\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.0172\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 329us/sample - loss: 0.0153\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 325us/sample - loss: 0.0133\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 323us/sample - loss: 0.0116\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0103\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 349us/sample - loss: 0.0095\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0091\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0091\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 0.0091\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0092\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0091\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0087\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 326us/sample - loss: 0.0082\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.0075\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 337us/sample - loss: 0.0067\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0060\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.0054\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0050\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 666us/sample - loss: 0.0047\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0045\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 325us/sample - loss: 0.0044\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0043\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 340us/sample - loss: 0.0042\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0040\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0037\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0034\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0031\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 332us/sample - loss: 0.0028\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0026\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0024\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 669us/sample - loss: 0.0022\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 342us/sample - loss: 0.0021\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0020\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0019\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0019\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0017\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0016\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 325us/sample - loss: 0.0015\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 0.0014\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0012\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0011\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 0.0010\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.7350e-04\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.1844e-04\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 341us/sample - loss: 8.6912e-04\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.1984e-04\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 660us/sample - loss: 7.6710e-04\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 7.1019e-04\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 6.5080e-04\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 5.9209e-04\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 665us/sample - loss: 5.3746e-04\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 4.8942e-04\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 324us/sample - loss: 4.4900e-04\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 4.1562e-04\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 3.8750e-04\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.6235e-04\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 3.3808e-04\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.1338e-04\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 676us/sample - loss: 2.8790e-04\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 657us/sample - loss: 2.6217e-04\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.3725e-04\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 327us/sample - loss: 2.1428e-04\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 326us/sample - loss: 1.9406e-04\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.7687e-04\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.6240e-04\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 335us/sample - loss: 1.4996e-04\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 668us/sample - loss: 1.3871e-04\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 666us/sample - loss: 1.2794e-04\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.1722e-04\n"
     ]
    }
   ],
   "source": [
    "IO = Dense(units=1, input_dim=1)\n",
    "model = Sequential([IO])\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(0.1))\n",
    "early = EarlyStopping(monitor='loss',min_delta=0.001, patience=16)\n",
    "h = model.fit(x,y,epochs=1000, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
